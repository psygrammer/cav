{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* Overview\n",
    "    - Goals\n",
    "    - Highlights of the Tutorial\n",
    "    - Model Architecture\n",
    "* Code Organization\n",
    "* CIFAR-10 Model\n",
    "    - Model inputs\n",
    "    - Model prediction\n",
    "    - Model training \n",
    "* Launching and Training the Model\n",
    "* Evaluating a Model\n",
    "* Training a Model Using Multiple GPU Cards\n",
    "    - Placing Variables and Operations on Devices\n",
    "    - Launching and Training the Model on Multiple GPU cards\n",
    "* Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고\n",
    "* [2] https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 환경설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tensorflow image (cpu + gpu) pulling\n",
    "    - docker pull b.gcr.io/tensorflow/tensorflow-devel-gpu\n",
    "* Ubuntu 리눅스 경우, [2]를 따라서 호스트 시스템 GPU 셋팅을 한다. \n",
    "* 그리고 도커를 다음 스크립트를 사용해서 연결\n",
    "    - (관련 스크립트) docker_run_gpu.sh\n",
    "* 이후 컨테이너 안에서 tensorboard 실행\n",
    "    - (관련 스크립트) run_tensorboard.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 환경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>lspci | grep -i nvidia</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">06:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] (rev a1)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>nvidia-smi</code> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/gpuusage.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 실습코드 \n",
    "* 실습 도커OS의 다음 경로에 예제 코드가 있음 \n",
    "    - /tensorflow/tensorflow/models/image/cifar10\n",
    "* 스터디 github 현재 경로에도(이 노트북과 같은 위치) 복사.\n",
    "* cifar10_eval_gpu.py는 cifar10_multi_gpu_train.py을 위한 원래 코드에서 설정을 조금 변경한 코드\n",
    "* 원 코드들의 로그 경로를(텐서보드용) 현재 경로상의 log 디렉토리로 변경.\n",
    "* 파이썬 코드들은 최대한 서버 터미널로 실행, 출력로그는 plog 확장자로 남김(노트북에서 실행하면 큰일) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar10.py\t     cifar10_input_test.py\t train.plog\r\n",
      "cifar10_eval.py      cifar10_multi_gpu_train.py  train_gpu.plog\r\n",
      "cifar10_eval_gpu.py  cifar10_train.py\r\n",
      "cifar10_input.py     eval_gpu.plog\r\n",
      "\r\n",
      "log:\r\n",
      "cifar10_eval  cifar10_eval_gpu\tcifar10_train  cifar10_train_gpu\r\n"
     ]
    }
   ],
   "source": [
    "!ls cifar10* log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_gpu.plog  train.plog  train_gpu.plog\r\n"
     ]
    }
   ],
   "source": [
    "!ls *.plog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oerview\n",
    "* Goals\n",
    "* Highlights of the Tutorial\n",
    "* Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is to classify RGB 32x32 pixel images across 10 categories: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.tensorflow.org/versions/0.6.0/images/cifar_samples.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this tutorial is to build a relatively small convolutional neural network (CNN) for recognizing images. In the process, this tutorial:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Highlights a canonical organization for network architecture, training and evaluation.\n",
    "2. Provides a template for constructing larger and more sophisticated models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlights of the Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Core mathematical components\n",
    "    - <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/nn.html#conv2d\">convolution</a>\n",
    "    - <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/nn.html#relu\">rectified linear activations</a>\n",
    "    - <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/nn.html#max_pool\">max pooling</a>\n",
    "    - <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/nn.html#local_response_normalization\">local response normalization</a>\n",
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/how_tos/summaries_and_tensorboard/index.html\">Visualization</a>\n",
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/train.html#ExponentialMovingAverage\">moving average</a>\n",
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/train.html#exponential_decay\">learning rate schedule</a>\n",
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/io_ops.html#shuffle_batch\">queues</a>\n",
    "* multi-GPU\n",
    "    - Configuring a model to train across multiple GPU cards in parallel\n",
    "    - Sharing and updating variables among multiple GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <a href=\"https://code.google.com/p/cuda-convnet/\">Alex Krizhevsky</a>\n",
    "* This model achieves a peak performance of about 86% accuracy within a few hours of training time on a GPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* code - https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/models/image/cifar10/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap_cnn.1.png\" width=600 />                                                                                                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Model\n",
    "* Model inputs -  inputs(), distorted_inputs()\n",
    "* Model prediction - inference()\n",
    "* Model training - loss(), train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/io_ops.html#FixedLengthRecordReader\">tf.FixedLengthRecordReader</a>\n",
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/how_tos/reading_data/index.html#reading-from-files\">Reading Data</a>\n",
    "* The images are processed as follows:\n",
    "    - 24 x 24 pixels, <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/image.html#random_crop\">randomly</a>\n",
    "    - <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/image.html#per_image_whitening\">approximately whitened</a>\n",
    "* For training, we additionally apply a series of random distortions to artificially increase the data set size:\n",
    "    - <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/image.html#random_flip_left_right\">Randomly flip</a>\n",
    "    - <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/image.html#random_brightness\">image brightness</a>\n",
    "    - <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/image.html#tf_image_random_contrast\">image contrast</a>\n",
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/image.html\">Images</a> \n",
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/train.html#image_summary\">image_summary</a>\n",
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/io_ops.html#shuffle_batch\">queue</a> - we run them inside 16 separate threads which continuously fill a TensorFlow queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap_cnn.2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### <font color=\"orange\"> cifar10_input.py </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cifar10_input.py\n",
    "\n",
    "\"\"\"Routine for decoding the CIFAR-10 binary file format.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow.python.platform\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def read_cifar10(filename_queue):\n",
    "  \"\"\"Reads and parses examples from CIFAR10 data files.\n",
    "\n",
    "  Recommendation: if you want N-way read parallelism, call this function\n",
    "  N times.  This will give you N independent Readers reading different\n",
    "  files & positions within those files, which will give better mixing of\n",
    "  examples.\n",
    "\n",
    "  Args:\n",
    "    filename_queue: A queue of strings with the filenames to read from.\n",
    "\n",
    "  Returns:\n",
    "    An object representing a single example, with the following fields:\n",
    "      height: number of rows in the result (32)\n",
    "      width: number of columns in the result (32)\n",
    "      depth: number of color channels in the result (3)\n",
    "      key: a scalar string Tensor describing the filename & record number\n",
    "        for this example.\n",
    "      label: an int32 Tensor with the label in the range 0..9.\n",
    "      uint8image: a [height, width, depth] uint8 Tensor with the image data\n",
    "  \"\"\"\n",
    "\n",
    "  class CIFAR10Record(object):\n",
    "    pass\n",
    "  result = CIFAR10Record()\n",
    "\n",
    "  # Dimensions of the images in the CIFAR-10 dataset.\n",
    "  # See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the\n",
    "  # input format.\n",
    "  label_bytes = 1  # 2 for CIFAR-100\n",
    "  result.height = 32\n",
    "  result.width = 32\n",
    "  result.depth = 3\n",
    "  image_bytes = result.height * result.width * result.depth\n",
    "  # Every record consists of a label followed by the image, with a\n",
    "  # fixed number of bytes for each.\n",
    "  record_bytes = label_bytes + image_bytes\n",
    "\n",
    "  # Read a record, getting filenames from the filename_queue.  No\n",
    "  # header or footer in the CIFAR-10 format, so we leave header_bytes\n",
    "  # and footer_bytes at their default of 0.\n",
    "  reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n",
    "  result.key, value = reader.read(filename_queue)\n",
    "\n",
    "  # Convert from a string to a vector of uint8 that is record_bytes long.\n",
    "  record_bytes = tf.decode_raw(value, tf.uint8)\n",
    "\n",
    "  # The first bytes represent the label, which we convert from uint8->int32.\n",
    "  result.label = tf.cast(\n",
    "      tf.slice(record_bytes, [0], [label_bytes]), tf.int32)\n",
    "\n",
    "  # The remaining bytes after the label represent the image, which we reshape\n",
    "  # from [depth * height * width] to [depth, height, width].\n",
    "  depth_major = tf.reshape(tf.slice(record_bytes, [label_bytes], [image_bytes]),\n",
    "                           [result.depth, result.height, result.width])\n",
    "  # Convert from [depth, height, width] to [height, width, depth].\n",
    "  result.uint8image = tf.transpose(depth_major, [1, 2, 0])\n",
    "\n",
    "  return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"orange\"> cifar10_input_test.py </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cifar10_input_test.py\n",
    "\n",
    "\"\"\"Tests for cifar10 input.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow.python.platform\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.models.image.cifar10 import cifar10_input\n",
    "\n",
    "\n",
    "class CIFAR10InputTest(tf.test.TestCase):\n",
    "\n",
    "  def _record(self, label, red, green, blue):\n",
    "    image_size = 32 * 32\n",
    "    record = bytes(bytearray([label] + [red] * image_size +\n",
    "                             [green] * image_size + [blue] * image_size))\n",
    "    expected = [[[red, green, blue]] * 32] * 32\n",
    "    return record, expected\n",
    "\n",
    "  def testSimple(self):\n",
    "    labels = [9, 3, 0]\n",
    "    records = [self._record(labels[0], 0, 128, 255),\n",
    "               self._record(labels[1], 255, 0, 1),\n",
    "               self._record(labels[2], 254, 255, 0)]\n",
    "    contents = b\"\".join([record for record, _ in records])\n",
    "    expected = [expected for _, expected in records]\n",
    "    filename = os.path.join(self.get_temp_dir(), \"cifar\")\n",
    "    open(filename, \"wb\").write(contents)\n",
    "\n",
    "    with self.test_session() as sess:\n",
    "      q = tf.FIFOQueue(99, [tf.string], shapes=())\n",
    "      q.enqueue([filename]).run()\n",
    "      q.close().run()\n",
    "      result = cifar10_input.read_cifar10(q)\n",
    "\n",
    "      for i in range(3):\n",
    "        key, label, uint8image = sess.run([\n",
    "            result.key, result.label, result.uint8image])\n",
    "        self.assertEqual(\"%s:%d\" % (filename, i), tf.compat.as_text(key))\n",
    "        self.assertEqual(labels[i], label)\n",
    "        self.assertAllEqual(expected[i], uint8image)\n",
    "\n",
    "      with self.assertRaises(tf.errors.OutOfRangeError):\n",
    "        sess.run([result.key, result.uint8image])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  tf.test.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 32\n",
      "I tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 0 with properties: \n",
      "name: Tesla K40m\n",
      "major: 3 minor: 5 memoryClockRate (GHz) 0.745\n",
      "pciBusID 0000:06:00.0\n",
      "Total memory: 11.25GiB\n",
      "Free memory: 11.12GiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: 0 \n",
      "I tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 0:   Y \n",
      "I tensorflow/core/common_runtime/gpu/gpu_device.cc:702] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40m, pci bus id: 0000:06:00.0)\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Allocating 3.34GiB bytes.\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:52] GPU 0 memory begins at 0x42047a0000 extends to 0x42da041ccc\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.0KiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.0KiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.0KiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.0KiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.0KiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.0KiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.0KiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.0KiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.0KiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.0KiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00MiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00MiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00MiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00MiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00MiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.00MiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.00MiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.00MiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.00MiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.00MiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00GiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00GiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00GiB\n",
      "I tensorflow/core/common_runtime/direct_session.cc:60] Direct session inter op parallelism threads: 32\n",
      "W tensorflow/core/common_runtime/executor.cc:1071] 0x2fdc320 Compute status: Out of range: FIFOQueue '_0_fifo_queue' is closed and has insufficient elements (requested 1, current size 0)\n",
      "\t [[Node: ReaderRead = ReaderRead[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](FixedLengthRecordReader, fifo_queue)]]\n",
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 2.878s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python cifar10_input_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/nn.html#conv2d\">convolution</a>\n",
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/nn.html#relu\">rectified linear activations</a>\n",
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/nn.html#max_pool\">max pooling</a>\n",
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/nn.html#local_response_normalization\">local response normalization</a>\n",
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/nn.html\">fully connected layer with rectified linear activation</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap_cnn.3.png\" width=600 /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap_cnn.4.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"orange\"> cifar10.py </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cifar10.py\n",
    "\n",
    "\"\"\"Builds the CIFAR-10 network.\n",
    "\n",
    "Summary of available functions:\n",
    "\n",
    " # Compute input images and labels for training. If you would like to run\n",
    " # evaluations, use input() instead.\n",
    " inputs, labels = distorted_inputs()\n",
    "\n",
    " # Compute inference on the model inputs to make a prediction.\n",
    " predictions = inference(inputs)\n",
    "\n",
    " # Compute the total loss of the prediction with respect to the labels.\n",
    " loss = loss(predictions, labels)\n",
    "\n",
    " # Create a graph to run one step of training with respect to the loss.\n",
    " train_op = train(loss, global_step)\n",
    "\"\"\"\n",
    "# pylint: disable=missing-docstring\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "\n",
    "import tensorflow.python.platform\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.models.image.cifar10 import cifar10_input\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "# Basic model parameters.\n",
    "tf.app.flags.DEFINE_integer('batch_size', 128,\n",
    "                            \"\"\"Number of images to process in a batch.\"\"\")\n",
    "tf.app.flags.DEFINE_string('data_dir', './log/cifar10_data',\n",
    "                           \"\"\"Path to the CIFAR-10 data directory.\"\"\")\n",
    "\n",
    "# Process images of this size. Note that this differs from the original CIFAR\n",
    "# image size of 32 x 32. If one alters this number, then the entire model\n",
    "# architecture will change and any model would need to be retrained.\n",
    "IMAGE_SIZE = 24\n",
    "\n",
    "# Global constants describing the CIFAR-10 data set.\n",
    "NUM_CLASSES = 10\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000\n",
    "\n",
    "# Constants describing the training process.\n",
    "MOVING_AVERAGE_DECAY = 0.9999     # The decay to use for the moving average.\n",
    "NUM_EPOCHS_PER_DECAY = 350.0      # Epochs after which learning rate decays.\n",
    "LEARNING_RATE_DECAY_FACTOR = 0.1  # Learning rate decay factor.\n",
    "INITIAL_LEARNING_RATE = 0.1       # Initial learning rate.\n",
    "\n",
    "# If a model is trained with multiple GPU's prefix all Op names with tower_name\n",
    "# to differentiate the operations. Note that this prefix is removed from the\n",
    "# names of the summaries when visualizing a model.\n",
    "TOWER_NAME = 'tower'\n",
    "\n",
    "DATA_URL = 'http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'\n",
    "\n",
    "\n",
    "def _activation_summary(x):\n",
    "  \"\"\"Helper to create summaries for activations.\n",
    "\n",
    "  Creates a summary that provides a histogram of activations.\n",
    "  Creates a summary that measure the sparsity of activations.\n",
    "\n",
    "  Args:\n",
    "    x: Tensor\n",
    "  Returns:\n",
    "    nothing\n",
    "  \"\"\"\n",
    "  # Remove 'tower_[0-9]/' from the name in case this is a multi-GPU training\n",
    "  # session. This helps the clarity of presentation on tensorboard.\n",
    "  tensor_name = re.sub('%s_[0-9]*/' % TOWER_NAME, '', x.op.name)\n",
    "  tf.histogram_summary(tensor_name + '/activations', x)\n",
    "  tf.scalar_summary(tensor_name + '/sparsity', tf.nn.zero_fraction(x))\n",
    "\n",
    "\n",
    "def _variable_on_cpu(name, shape, initializer):\n",
    "  \"\"\"Helper to create a Variable stored on CPU memory.\n",
    "\n",
    "  Args:\n",
    "    name: name of the variable\n",
    "    shape: list of ints\n",
    "    initializer: initializer for Variable\n",
    "\n",
    "  Returns:\n",
    "    Variable Tensor\n",
    "  \"\"\"\n",
    "  with tf.device('/cpu:0'):\n",
    "    var = tf.get_variable(name, shape, initializer=initializer)\n",
    "  return var\n",
    "\n",
    "\n",
    "def _variable_with_weight_decay(name, shape, stddev, wd):\n",
    "  \"\"\"Helper to create an initialized Variable with weight decay.\n",
    "\n",
    "  Note that the Variable is initialized with a truncated normal distribution.\n",
    "  A weight decay is added only if one is specified.\n",
    "\n",
    "  Args:\n",
    "    name: name of the variable\n",
    "    shape: list of ints\n",
    "    stddev: standard deviation of a truncated Gaussian\n",
    "    wd: add L2Loss weight decay multiplied by this float. If None, weight\n",
    "        decay is not added for this Variable.\n",
    "\n",
    "  Returns:\n",
    "    Variable Tensor\n",
    "  \"\"\"\n",
    "  var = _variable_on_cpu(name, shape,\n",
    "                         tf.truncated_normal_initializer(stddev=stddev))\n",
    "  if wd:\n",
    "    weight_decay = tf.mul(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "    tf.add_to_collection('losses', weight_decay)\n",
    "  return var\n",
    "\n",
    "\n",
    "def _generate_image_and_label_batch(image, label, min_queue_examples):\n",
    "  \"\"\"Construct a queued batch of images and labels.\n",
    "\n",
    "  Args:\n",
    "    image: 3-D Tensor of [IMAGE_SIZE, IMAGE_SIZE, 3] of type.float32.\n",
    "    label: 1-D Tensor of type.int32\n",
    "    min_queue_examples: int32, minimum number of samples to retain\n",
    "      in the queue that provides of batches of examples.\n",
    "\n",
    "  Returns:\n",
    "    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "    labels: Labels. 1D tensor of [batch_size] size.\n",
    "  \"\"\"\n",
    "  # Create a queue that shuffles the examples, and then\n",
    "  # read 'FLAGS.batch_size' images + labels from the example queue.\n",
    "  num_preprocess_threads = 16\n",
    "  images, label_batch = tf.train.shuffle_batch(\n",
    "      [image, label],\n",
    "      batch_size=FLAGS.batch_size,\n",
    "      num_threads=num_preprocess_threads,\n",
    "      capacity=min_queue_examples + 3 * FLAGS.batch_size,\n",
    "      min_after_dequeue=min_queue_examples)\n",
    "\n",
    "  # Display the training images in the visualizer.\n",
    "  tf.image_summary('images', images)\n",
    "\n",
    "  return images, tf.reshape(label_batch, [FLAGS.batch_size])\n",
    "\n",
    "\n",
    "def distorted_inputs():\n",
    "  \"\"\"Construct distorted input for CIFAR training using the Reader ops.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: if no data_dir\n",
    "\n",
    "  Returns:\n",
    "    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "    labels: Labels. 1D tensor of [batch_size] size.\n",
    "  \"\"\"\n",
    "  filenames = [os.path.join(FLAGS.data_dir, 'cifar-10-batches-bin',\n",
    "                            'data_batch_%d.bin' % i)\n",
    "               for i in xrange(1, 5)]\n",
    "  for f in filenames:\n",
    "    if not gfile.Exists(f):\n",
    "      raise ValueError('Failed to find file: ' + f)\n",
    "\n",
    "  # Create a queue that produces the filenames to read.\n",
    "  filename_queue = tf.train.string_input_producer(filenames)\n",
    "\n",
    "  # Read examples from files in the filename queue.\n",
    "  read_input = cifar10_input.read_cifar10(filename_queue)\n",
    "  reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n",
    "\n",
    "  height = IMAGE_SIZE\n",
    "  width = IMAGE_SIZE\n",
    "\n",
    "  # Image processing for training the network. Note the many random\n",
    "  # distortions applied to the image.\n",
    "\n",
    "  # Randomly crop a [height, width] section of the image.\n",
    "  distorted_image = tf.image.random_crop(reshaped_image, [height, width])\n",
    "\n",
    "  # Randomly flip the image horizontally.\n",
    "  distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "\n",
    "  # Because these operations are not commutative, consider randomizing\n",
    "  # randomize the order their operation.\n",
    "  distorted_image = tf.image.random_brightness(distorted_image,\n",
    "                                               max_delta=63)\n",
    "  distorted_image = tf.image.random_contrast(distorted_image,\n",
    "                                             lower=0.2, upper=1.8)\n",
    "\n",
    "  # Subtract off the mean and divide by the variance of the pixels.\n",
    "  float_image = tf.image.per_image_whitening(distorted_image)\n",
    "\n",
    "  # Ensure that the random shuffling has good mixing properties.\n",
    "  min_fraction_of_examples_in_queue = 0.4\n",
    "  min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN *\n",
    "                           min_fraction_of_examples_in_queue)\n",
    "  print ('Filling queue with %d CIFAR images before starting to train. '\n",
    "         'This will take a few minutes.' % min_queue_examples)\n",
    "\n",
    "  # Generate a batch of images and labels by building up a queue of examples.\n",
    "  return _generate_image_and_label_batch(float_image, read_input.label,\n",
    "                                         min_queue_examples)\n",
    "\n",
    "\n",
    "def inputs(eval_data):\n",
    "  \"\"\"Construct input for CIFAR evaluation using the Reader ops.\n",
    "\n",
    "  Args:\n",
    "    eval_data: bool, indicating if one should use the train or eval data set.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: if no data_dir\n",
    "\n",
    "  Returns:\n",
    "    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "    labels: Labels. 1D tensor of [batch_size] size.\n",
    "  \"\"\"\n",
    "  if not FLAGS.data_dir:\n",
    "    raise ValueError('Please supply a data_dir')\n",
    "\n",
    "  if not eval_data:\n",
    "    filenames = [os.path.join(FLAGS.data_dir, 'cifar-10-batches-bin',\n",
    "                              'data_batch_%d.bin' % i)\n",
    "                 for i in xrange(1, 5)]\n",
    "    num_examples_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN\n",
    "  else:\n",
    "    filenames = [os.path.join(FLAGS.data_dir, 'cifar-10-batches-bin',\n",
    "                              'test_batch.bin')]\n",
    "    num_examples_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_EVAL\n",
    "\n",
    "  for f in filenames:\n",
    "    if not gfile.Exists(f):\n",
    "      raise ValueError('Failed to find file: ' + f)\n",
    "\n",
    "  # Create a queue that produces the filenames to read.\n",
    "  filename_queue = tf.train.string_input_producer(filenames)\n",
    "\n",
    "  # Read examples from files in the filename queue.\n",
    "  read_input = cifar10_input.read_cifar10(filename_queue)\n",
    "  reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n",
    "\n",
    "  height = IMAGE_SIZE\n",
    "  width = IMAGE_SIZE\n",
    "\n",
    "  # Image processing for evaluation.\n",
    "  # Crop the central [height, width] of the image.\n",
    "  resized_image = tf.image.resize_image_with_crop_or_pad(reshaped_image,\n",
    "                                                         width, height)\n",
    "\n",
    "  # Subtract off the mean and divide by the variance of the pixels.\n",
    "  float_image = tf.image.per_image_whitening(resized_image)\n",
    "\n",
    "  # Ensure that the random shuffling has good mixing properties.\n",
    "  min_fraction_of_examples_in_queue = 0.4\n",
    "  min_queue_examples = int(num_examples_per_epoch *\n",
    "                           min_fraction_of_examples_in_queue)\n",
    "\n",
    "  # Generate a batch of images and labels by building up a queue of examples.\n",
    "  return _generate_image_and_label_batch(float_image, read_input.label,\n",
    "                                         min_queue_examples)\n",
    "\n",
    "\n",
    "def inference(images):\n",
    "  \"\"\"Build the CIFAR-10 model.\n",
    "\n",
    "  Args:\n",
    "    images: Images returned from distorted_inputs() or inputs().\n",
    "\n",
    "  Returns:\n",
    "    Logits.\n",
    "  \"\"\"\n",
    "  # We instantiate all variables using tf.get_variable() instead of\n",
    "  # tf.Variable() in order to share variables across multiple GPU training runs.\n",
    "  # If we only ran this model on a single GPU, we could simplify this function\n",
    "  # by replacing all instances of tf.get_variable() with tf.Variable().\n",
    "  #\n",
    "  # conv1\n",
    "  with tf.variable_scope('conv1') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights', shape=[5, 5, 3, 64],\n",
    "                                         stddev=1e-4, wd=0.0)\n",
    "    conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0))\n",
    "    bias = tf.nn.bias_add(conv, biases)\n",
    "    conv1 = tf.nn.relu(bias, name=scope.name)\n",
    "    _activation_summary(conv1)\n",
    "\n",
    "  # pool1\n",
    "  pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='SAME', name='pool1')\n",
    "  # norm1\n",
    "  norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                    name='norm1')\n",
    "\n",
    "  # conv2\n",
    "  with tf.variable_scope('conv2') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights', shape=[5, 5, 64, 64],\n",
    "                                         stddev=1e-4, wd=0.0)\n",
    "    conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\n",
    "    bias = tf.nn.bias_add(conv, biases)\n",
    "    conv2 = tf.nn.relu(bias, name=scope.name)\n",
    "    _activation_summary(conv2)\n",
    "\n",
    "  # norm2\n",
    "  norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                    name='norm2')\n",
    "  # pool2\n",
    "  pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1],\n",
    "                         strides=[1, 2, 2, 1], padding='SAME', name='pool2')\n",
    "\n",
    "  # local3\n",
    "  with tf.variable_scope('local3') as scope:\n",
    "    # Move everything into depth so we can perform a single matrix multiply.\n",
    "    dim = 1\n",
    "    for d in pool2.get_shape()[1:].as_list():\n",
    "      dim *= d\n",
    "    reshape = tf.reshape(pool2, [FLAGS.batch_size, dim])\n",
    "\n",
    "    weights = _variable_with_weight_decay('weights', shape=[dim, 384],\n",
    "                                          stddev=0.04, wd=0.004)\n",
    "    biases = _variable_on_cpu('biases', [384], tf.constant_initializer(0.1))\n",
    "    local3 = tf.nn.relu_layer(reshape, weights, biases, name=scope.name)\n",
    "    _activation_summary(local3)\n",
    "\n",
    "  # local4\n",
    "  with tf.variable_scope('local4') as scope:\n",
    "    weights = _variable_with_weight_decay('weights', shape=[384, 192],\n",
    "                                          stddev=0.04, wd=0.004)\n",
    "    biases = _variable_on_cpu('biases', [192], tf.constant_initializer(0.1))\n",
    "    local4 = tf.nn.relu_layer(local3, weights, biases, name=scope.name)\n",
    "    _activation_summary(local4)\n",
    "\n",
    "  # softmax, i.e. softmax(WX + b)\n",
    "  with tf.variable_scope('softmax_linear') as scope:\n",
    "    weights = _variable_with_weight_decay('weights', [192, NUM_CLASSES],\n",
    "                                          stddev=1/192.0, wd=0.0)\n",
    "    biases = _variable_on_cpu('biases', [NUM_CLASSES],\n",
    "                              tf.constant_initializer(0.0))\n",
    "    softmax_linear = tf.nn.xw_plus_b(local4, weights, biases, name=scope.name)\n",
    "    _activation_summary(softmax_linear)\n",
    "\n",
    "  return softmax_linear\n",
    "\n",
    "\n",
    "def loss(logits, labels):\n",
    "  \"\"\"Add L2Loss to all the trainable variables.\n",
    "\n",
    "  Add summary for for \"Loss\" and \"Loss/avg\".\n",
    "  Args:\n",
    "    logits: Logits from inference().\n",
    "    labels: Labels from distorted_inputs or inputs(). 1-D tensor\n",
    "            of shape [batch_size]\n",
    "\n",
    "  Returns:\n",
    "    Loss tensor of type float.\n",
    "  \"\"\"\n",
    "  # Reshape the labels into a dense Tensor of\n",
    "  # shape [batch_size, NUM_CLASSES].\n",
    "  sparse_labels = tf.reshape(labels, [FLAGS.batch_size, 1])\n",
    "  indices = tf.reshape(tf.range(FLAGS.batch_size), [FLAGS.batch_size, 1])\n",
    "  concated = tf.concat(1, [indices, sparse_labels])\n",
    "  dense_labels = tf.sparse_to_dense(concated,\n",
    "                                    [FLAGS.batch_size, NUM_CLASSES],\n",
    "                                    1.0, 0.0)\n",
    "\n",
    "  # Calculate the average cross entropy loss across the batch.\n",
    "  cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "      logits, dense_labels, name='cross_entropy_per_example')\n",
    "  cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "  tf.add_to_collection('losses', cross_entropy_mean)\n",
    "\n",
    "  # The total loss is defined as the cross entropy loss plus all of the weight\n",
    "  # decay terms (L2 loss).\n",
    "  return tf.add_n(tf.get_collection('losses'), name='total_loss')\n",
    "\n",
    "\n",
    "def _add_loss_summaries(total_loss):\n",
    "  \"\"\"Add summaries for losses in CIFAR-10 model.\n",
    "\n",
    "  Generates moving average for all losses and associated summaries for\n",
    "  visualizing the performance of the network.\n",
    "\n",
    "  Args:\n",
    "    total_loss: Total loss from loss().\n",
    "  Returns:\n",
    "    loss_averages_op: op for generating moving averages of losses.\n",
    "  \"\"\"\n",
    "  # Compute the moving average of all individual losses and the total loss.\n",
    "  loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')\n",
    "  losses = tf.get_collection('losses')\n",
    "  loss_averages_op = loss_averages.apply(losses + [total_loss])\n",
    "\n",
    "  # Attach a scalar summmary to all individual losses and the total loss; do the\n",
    "  # same for the averaged version of the losses.\n",
    "  for l in losses + [total_loss]:\n",
    "    # Name each loss as '(raw)' and name the moving average version of the loss\n",
    "    # as the original loss name.\n",
    "    tf.scalar_summary(l.op.name +' (raw)', l)\n",
    "    tf.scalar_summary(l.op.name, loss_averages.average(l))\n",
    "\n",
    "  return loss_averages_op\n",
    "\n",
    "\n",
    "def train(total_loss, global_step):\n",
    "  \"\"\"Train CIFAR-10 model.\n",
    "\n",
    "  Create an optimizer and apply to all trainable variables. Add moving\n",
    "  average for all trainable variables.\n",
    "\n",
    "  Args:\n",
    "    total_loss: Total loss from loss().\n",
    "    global_step: Integer Variable counting the number of training steps\n",
    "      processed.\n",
    "  Returns:\n",
    "    train_op: op for training.\n",
    "  \"\"\"\n",
    "  # Variables that affect learning rate.\n",
    "  num_batches_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN / FLAGS.batch_size\n",
    "  decay_steps = int(num_batches_per_epoch * NUM_EPOCHS_PER_DECAY)\n",
    "\n",
    "  # Decay the learning rate exponentially based on the number of steps.\n",
    "  lr = tf.train.exponential_decay(INITIAL_LEARNING_RATE,\n",
    "                                  global_step,\n",
    "                                  decay_steps,\n",
    "                                  LEARNING_RATE_DECAY_FACTOR,\n",
    "                                  staircase=True)\n",
    "  tf.scalar_summary('learning_rate', lr)\n",
    "\n",
    "  # Generate moving averages of all losses and associated summaries.\n",
    "  loss_averages_op = _add_loss_summaries(total_loss)\n",
    "\n",
    "  # Compute gradients.\n",
    "  with tf.control_dependencies([loss_averages_op]):\n",
    "    opt = tf.train.GradientDescentOptimizer(lr)\n",
    "    grads = opt.compute_gradients(total_loss)\n",
    "\n",
    "  # Apply gradients.\n",
    "  apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "  # Add histograms for trainable variables.\n",
    "  for var in tf.trainable_variables():\n",
    "    tf.histogram_summary(var.op.name, var)\n",
    "\n",
    "  # Add histograms for gradients.\n",
    "  for grad, var in grads:\n",
    "    if grad:\n",
    "      tf.histogram_summary(var.op.name + '/gradients', grad)\n",
    "\n",
    "  # Track the moving averages of all trainable variables.\n",
    "  variable_averages = tf.train.ExponentialMovingAverage(\n",
    "      MOVING_AVERAGE_DECAY, global_step)\n",
    "  variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "\n",
    "  with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n",
    "    train_op = tf.no_op(name='train')\n",
    "\n",
    "  return train_op\n",
    "\n",
    "\n",
    "def maybe_download_and_extract():\n",
    "  \"\"\"Download and extract the tarball from Alex's website.\"\"\"\n",
    "  dest_directory = FLAGS.data_dir\n",
    "  if not os.path.exists(dest_directory):\n",
    "    os.makedirs(dest_directory)\n",
    "  filename = DATA_URL.split('/')[-1]\n",
    "  filepath = os.path.join(dest_directory, filename)\n",
    "  if not os.path.exists(filepath):\n",
    "    def _progress(count, block_size, total_size):\n",
    "      sys.stdout.write('\\r>> Downloading %s %.1f%%' % (filename,\n",
    "          float(count * block_size) / float(total_size) * 100.0))\n",
    "      sys.stdout.flush()\n",
    "    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath,\n",
    "                                             reporthook=_progress)\n",
    "    print()\n",
    "    statinfo = os.stat(filepath)\n",
    "    print('Succesfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "    tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <a href=\"https://en.wikipedia.org/wiki/Multinomial_logistic_regression\">multinomial logistic regression</a>\n",
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/nn.html#softmax\">softmax</a>\n",
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/nn.html#softmax_cross_entropy_with_logits\">cross-entropy</a>\n",
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/sparse_ops.html#sparse_to_dense\">1-hot encoding</a>\n",
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/nn.html#l2_loss\">weight decay</a>\n",
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/train.html#scalar_summary\">scalar_summary</a>\n",
    "* <a href=\"https://en.wikipedia.org/wiki/Gradient_descent\">gradient descent</a>\n",
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/train.html\">Training</a>\n",
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/train.html#exponential_decay\">exponentially decays</a>\n",
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/train.html#GradientDescentOptimizer\">GradientDescentOptimizer</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap_cnn.5.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap_cnn.6.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launching and Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/api_docs/python/state_ops.html#Saver\">saves</a> \n",
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/how_tos/variables/index.html#saving-and-restoring\">checkpoint files</a>\n",
    "* <a href=\"https://www.tensorflow.org/versions/v0.6.0/tutorials/deep_cnn/index.html#evaluating-a-model\">Evaluating a Model</a>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 콘솔에서 실행하자\n",
    "python cifar10_train.py > train.plog 2>train.plog &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\r\n",
      "2016-02-03 09:49:56.909836: step 0, loss = 4.67 (2.0 examples/sec; 65.123 sec/batch)\r\n",
      "2016-02-03 09:50:02.208112: step 10, loss = 4.66 (272.5 examples/sec; 0.470 sec/batch)\r\n",
      "2016-02-03 09:50:06.935291: step 20, loss = 4.63 (309.4 examples/sec; 0.414 sec/batch)\r\n",
      "2016-02-03 09:50:11.677843: step 30, loss = 4.61 (269.0 examples/sec; 0.476 sec/batch)\r\n",
      "2016-02-03 09:50:16.492321: step 40, loss = 4.59 (261.3 examples/sec; 0.490 sec/batch)\r\n",
      "2016-02-03 09:50:21.212418: step 50, loss = 4.57 (286.6 examples/sec; 0.447 sec/batch)\r\n",
      "2016-02-03 09:50:25.903630: step 60, loss = 4.56 (289.0 examples/sec; 0.443 sec/batch)\r\n",
      "2016-02-03 09:50:30.640395: step 70, loss = 4.54 (277.4 examples/sec; 0.461 sec/batch)\r\n",
      "2016-02-03 09:50:35.276647: step 80, loss = 4.52 (287.4 examples/sec; 0.445 sec/batch)\r\n"
     ]
    }
   ],
   "source": [
    "!head train.plog -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"orange\"> cifar10_train.py </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cifar10_train.py\n",
    "\n",
    "\"\"\"A binary to train CIFAR-10 using a single GPU.\n",
    "\n",
    "Accuracy:\n",
    "cifar10_train.py achieves ~86% accuracy after 100K steps (256 epochs of\n",
    "data) as judged by cifar10_eval.py.\n",
    "\n",
    "Speed: With batch_size 128.\n",
    "\n",
    "System        | Step Time (sec/batch)  |     Accuracy\n",
    "------------------------------------------------------------------\n",
    "1 Tesla K20m  | 0.35-0.60              | ~86% at 60K steps  (5 hours)\n",
    "1 Tesla K40m  | 0.25-0.35              | ~86% at 100K steps (4 hours)\n",
    "\n",
    "Usage:\n",
    "Please see the tutorial and website for how to download the CIFAR-10\n",
    "data set, compile the program and train the model.\n",
    "\n",
    "http://tensorflow.org/tutorials/deep_cnn/\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "import time\n",
    "\n",
    "import tensorflow.python.platform\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.models.image.cifar10 import cifar10\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string('train_dir', './log/cifar10_train',\n",
    "                           \"\"\"Directory where to write event logs \"\"\"\n",
    "                           \"\"\"and checkpoint.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('max_steps', 1000000,\n",
    "                            \"\"\"Number of batches to run.\"\"\")\n",
    "tf.app.flags.DEFINE_boolean('log_device_placement', False,\n",
    "                            \"\"\"Whether to log device placement.\"\"\")\n",
    "\n",
    "\n",
    "def train():\n",
    "  \"\"\"Train CIFAR-10 for a number of steps.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "    # Get images and labels for CIFAR-10.\n",
    "    images, labels = cifar10.distorted_inputs()\n",
    "\n",
    "    # Build a Graph that computes the logits predictions from the\n",
    "    # inference model.\n",
    "    logits = cifar10.inference(images)\n",
    "\n",
    "    # Calculate loss.\n",
    "    loss = cifar10.loss(logits, labels)\n",
    "\n",
    "    # Build a Graph that trains the model with one batch of examples and\n",
    "    # updates the model parameters.\n",
    "    train_op = cifar10.train(loss, global_step)\n",
    "\n",
    "    # Create a saver.\n",
    "    saver = tf.train.Saver(tf.all_variables())\n",
    "\n",
    "    # Build the summary operation based on the TF collection of Summaries.\n",
    "    summary_op = tf.merge_all_summaries()\n",
    "\n",
    "    # Build an initialization operation to run below.\n",
    "    init = tf.initialize_all_variables()\n",
    "\n",
    "    # Start running operations on the Graph.\n",
    "    sess = tf.Session(config=tf.ConfigProto(\n",
    "        log_device_placement=FLAGS.log_device_placement))\n",
    "    sess.run(init)\n",
    "\n",
    "    # Start the queue runners.\n",
    "    tf.train.start_queue_runners(sess=sess)\n",
    "\n",
    "    summary_writer = tf.train.SummaryWriter(FLAGS.train_dir,\n",
    "                                            graph_def=sess.graph_def)\n",
    "\n",
    "    for step in xrange(FLAGS.max_steps):\n",
    "      start_time = time.time()\n",
    "      _, loss_value = sess.run([train_op, loss])\n",
    "      duration = time.time() - start_time\n",
    "\n",
    "      assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "\n",
    "      if step % 10 == 0:\n",
    "        num_examples_per_step = FLAGS.batch_size\n",
    "        examples_per_sec = num_examples_per_step / duration\n",
    "        sec_per_batch = float(duration)\n",
    "\n",
    "        format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\n",
    "                      'sec/batch)')\n",
    "        print (format_str % (datetime.now(), step, loss_value,\n",
    "                             examples_per_sec, sec_per_batch))\n",
    "\n",
    "      if step % 100 == 0:\n",
    "        summary_str = sess.run(summary_op)\n",
    "        summary_writer.add_summary(summary_str, step)\n",
    "\n",
    "      # Save the model checkpoint periodically.\n",
    "      if step % 1000 == 0 or (step + 1) == FLAGS.max_steps:\n",
    "        checkpoint_path = os.path.join(FLAGS.train_dir, 'model.ckpt')\n",
    "        saver.save(sess, checkpoint_path, global_step=step)\n",
    "\n",
    "\n",
    "def main(argv=None):  # pylint: disable=unused-argument\n",
    "  cifar10.maybe_download_and_extract()\n",
    "  if gfile.Exists(FLAGS.train_dir):\n",
    "    gfile.DeleteRecursively(FLAGS.train_dir)\n",
    "  gfile.MakeDirs(FLAGS.train_dir)\n",
    "  train()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.app.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The terminal text returned from cifar10_train.py provides minimal insight into how the model is training. We want more insight into the model during training:\n",
    "* Is the loss really decreasing or is that just noise?\n",
    "* Is the model being provided appropriate images?\n",
    "* Are the gradients, activations and weights reasonable?\n",
    "* What is the learning rate currently at?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap_cnn.7.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <a href=\"\">TensorBoard</a>\n",
    "* <a href=\"\">SummaryWriter</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap_cnn.8.png\" /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 콘솔에서 실행하자\n",
    "python cifar10_eval.py > eval.plog 2> eval.plog &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행로그가 지워짐. 멀티gpu 버전으로 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 32\r\n",
      "I tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 0 with properties: \r\n",
      "name: Tesla K40m\r\n",
      "major: 3 minor: 5 memoryClockRate (GHz) 0.745\r\n",
      "pciBusID 0000:06:00.0\r\n",
      "Total memory: 11.25GiB\r\n",
      "Free memory: 11.12GiB\r\n",
      "I tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: 0 \r\n",
      "I tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 0:   Y \r\n",
      "I tensorflow/core/common_runtime/gpu/gpu_device.cc:702] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40m, pci bus id: 0000:06:00.0)\r\n"
     ]
    }
   ],
   "source": [
    "!head eval_gpu.plog -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=cnn_tensorboard/TensorBoard_0.html width=1000 height=900></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML('<iframe src=cnn_tensorboard/TensorBoard_0.html width=1000 height=900></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"orange\"> cifar10_eval.py </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Evaluation for CIFAR-10.\n",
    "\n",
    "Accuracy:\n",
    "cifar10_train.py achieves 83.0% accuracy after 100K steps (256 epochs\n",
    "of data) as judged by cifar10_eval.py.\n",
    "\n",
    "Speed:\n",
    "On a single Tesla K40, cifar10_train.py processes a single batch of 128 images\n",
    "in 0.25-0.35 sec (i.e. 350 - 600 images /sec). The model reaches ~86%\n",
    "accuracy after 100K steps in 8 hours of training time.\n",
    "\n",
    "Usage:\n",
    "Please see the tutorial and website for how to download the CIFAR-10\n",
    "data set, compile the program and train the model.\n",
    "\n",
    "http://tensorflow.org/tutorials/deep_cnn/\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "\n",
    "import tensorflow.python.platform\n",
    "from tensorflow.python.platform import gfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.models.image.cifar10 import cifar10\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string('eval_dir', './log/cifar10_eval',\n",
    "                           \"\"\"Directory where to write event logs.\"\"\")\n",
    "tf.app.flags.DEFINE_string('eval_data', 'test',\n",
    "                           \"\"\"Either 'test' or 'train_eval'.\"\"\")\n",
    "tf.app.flags.DEFINE_string('checkpoint_dir', './log/cifar10_train',\n",
    "                           \"\"\"Directory where to read model checkpoints.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('eval_interval_secs', 60 * 5,\n",
    "                            \"\"\"How often to run the eval.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('num_examples', 10000,\n",
    "                            \"\"\"Number of examples to run.\"\"\")\n",
    "tf.app.flags.DEFINE_boolean('run_once', False,\n",
    "                         \"\"\"Whether to run eval only once.\"\"\")\n",
    "\n",
    "\n",
    "def eval_once(saver, summary_writer, top_k_op, summary_op):\n",
    "  \"\"\"Run Eval once.\n",
    "\n",
    "  Args:\n",
    "    saver: Saver.\n",
    "    summary_writer: Summary writer.\n",
    "    top_k_op: Top K op.\n",
    "    summary_op: Summary op.\n",
    "  \"\"\"\n",
    "  with tf.Session() as sess:\n",
    "    ckpt = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "      # Restores from checkpoint\n",
    "      saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "      # Assuming model_checkpoint_path looks something like:\n",
    "      #   /my-favorite-path/cifar10_train/model.ckpt-0,\n",
    "      # extract global_step from it.\n",
    "      global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "    else:\n",
    "      print('No checkpoint file found')\n",
    "      return\n",
    "\n",
    "    # Start the queue runners.\n",
    "    coord = tf.train.Coordinator()\n",
    "    try:\n",
    "      threads = []\n",
    "      for qr in tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS):\n",
    "        threads.extend(qr.create_threads(sess, coord=coord, daemon=True,\n",
    "                                         start=True))\n",
    "\n",
    "      num_iter = int(math.ceil(FLAGS.num_examples / FLAGS.batch_size))\n",
    "      true_count = 0  # Counts the number of correct predictions.\n",
    "      total_sample_count = num_iter * FLAGS.batch_size\n",
    "      step = 0\n",
    "      while step < num_iter and not coord.should_stop():\n",
    "        predictions = sess.run([top_k_op])\n",
    "        true_count += np.sum(predictions)\n",
    "        step += 1\n",
    "\n",
    "      # Compute precision @ 1.\n",
    "      precision = true_count / total_sample_count\n",
    "      print('%s: precision @ 1 = %.3f' % (datetime.now(), precision))\n",
    "\n",
    "      summary = tf.Summary()\n",
    "      summary.ParseFromString(sess.run(summary_op))\n",
    "      summary.value.add(tag='Precision @ 1', simple_value=precision)\n",
    "      summary_writer.add_summary(summary, global_step)\n",
    "    except Exception as e:  # pylint: disable=broad-except\n",
    "      coord.request_stop(e)\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads, stop_grace_period_secs=10)\n",
    "\n",
    "\n",
    "def evaluate():\n",
    "  \"\"\"Eval CIFAR-10 for a number of steps.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    # Get images and labels for CIFAR-10.\n",
    "    eval_data = FLAGS.eval_data == 'test'\n",
    "    images, labels = cifar10.inputs(eval_data=eval_data)\n",
    "\n",
    "    # Build a Graph that computes the logits predictions from the\n",
    "    # inference model.\n",
    "    logits = cifar10.inference(images)\n",
    "\n",
    "    # Calculate predictions.\n",
    "    top_k_op = tf.nn.in_top_k(logits, labels, 1)\n",
    "\n",
    "    # Restore the moving average version of the learned variables for eval.\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(\n",
    "        cifar10.MOVING_AVERAGE_DECAY)\n",
    "    variables_to_restore = {}\n",
    "    for v in tf.all_variables():\n",
    "      if v in tf.trainable_variables():\n",
    "        restore_name = variable_averages.average_name(v)\n",
    "      else:\n",
    "        restore_name = v.op.name\n",
    "      variables_to_restore[restore_name] = v\n",
    "    saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "    # Build the summary operation based on the TF collection of Summaries.\n",
    "    summary_op = tf.merge_all_summaries()\n",
    "\n",
    "    graph_def = tf.get_default_graph().as_graph_def()\n",
    "    summary_writer = tf.train.SummaryWriter(FLAGS.eval_dir,\n",
    "                                            graph_def=graph_def)\n",
    "\n",
    "    while True:\n",
    "      eval_once(saver, summary_writer, top_k_op, summary_op)\n",
    "      if FLAGS.run_once:\n",
    "        break\n",
    "      time.sleep(FLAGS.eval_interval_secs)\n",
    "\n",
    "\n",
    "def main(argv=None):  # pylint: disable=unused-argument\n",
    "  cifar10.maybe_download_and_extract()\n",
    "  if gfile.Exists(FLAGS.eval_dir):\n",
    "    gfile.DeleteRecursively(FLAGS.eval_dir)\n",
    "  gfile.MakeDirs(FLAGS.eval_dir)\n",
    "  evaluate()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.app.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Model Using Multiple GPU Cards\n",
    "* Placing Variables and Operations on Devices\n",
    "* Launching and Training the Model on Multiple GPU cards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap_cnn.9.png\" width=600 /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placing Variables and Operations on Devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching and Training the Model on Multiple GPU cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 콘솔에서 실행하자\n",
    "python cifar10_multi_gpu_train.py > train_gpu.plog 2> train_gpu.plog &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\r\n",
      "2016-02-04 09:17:24.035597: step 0, loss = 4.67 (2.2 examples/sec; 58.901 sec/batch)\r\n",
      "2016-02-04 09:17:28.580393: step 10, loss = 4.66 (333.4 examples/sec; 0.384 sec/batch)\r\n",
      "2016-02-04 09:17:32.810022: step 20, loss = 4.63 (304.3 examples/sec; 0.421 sec/batch)\r\n",
      "2016-02-04 09:17:36.940751: step 30, loss = 4.61 (329.7 examples/sec; 0.388 sec/batch)\r\n",
      "2016-02-04 09:17:41.221532: step 40, loss = 4.60 (292.7 examples/sec; 0.437 sec/batch)\r\n",
      "2016-02-04 09:17:45.635159: step 50, loss = 4.58 (288.3 examples/sec; 0.444 sec/batch)\r\n",
      "2016-02-04 09:17:50.022579: step 60, loss = 4.57 (279.1 examples/sec; 0.459 sec/batch)\r\n",
      "2016-02-04 09:17:54.182997: step 70, loss = 4.55 (298.8 examples/sec; 0.428 sec/batch)\r\n",
      "2016-02-04 09:17:58.461537: step 80, loss = 4.53 (310.8 examples/sec; 0.412 sec/batch)\r\n"
     ]
    }
   ],
   "source": [
    "!head train_gpu.plog -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 참고자료\n",
    "* [1]\n",
    "* [2] https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

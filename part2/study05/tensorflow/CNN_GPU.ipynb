{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* Overview\n",
    "* Highlights of the Tutorial\n",
    "* CIFAR-10 Model\n",
    "    - Model inputs\n",
    "    - Model prediction\n",
    "    - Model training \n",
    "* Launching and Training the Model\n",
    "* Evaluating a Model\n",
    "* Training a Model Using Multiple GPU Cards\n",
    "    - Placing Variables and Operations on Devices\n",
    "    - Launching and Training the Model on Multiple GPU cards\n",
    "* Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고\n",
    "* [2] https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 환경설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tensorflow image (cpu + gpu) pulling\n",
    "    - docker pull b.gcr.io/tensorflow/tensorflow-devel-gpu\n",
    "* Ubuntu 리눅스 경우, [2]를 따라서 호스트 시스템 GPU 셋팅을 한다. \n",
    "* 그리고 도커를 다음 스크립트를 사용해서 연결\n",
    "    - (관련 스크립트) docker_run_gpu.sh\n",
    "* 이후 컨테이너 안에서 tensorboard 실행\n",
    "    - (관련 스크립트) run_tensorboard.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 환경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>lspci | grep -i nvidia</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">06:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] (rev a1)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>nvidia-smi</code> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/gpuusage.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 실습코드 \n",
    "* 실습 도커OS의 다음 경로에 예제 코드가 있음 \n",
    "    - /tensorflow/tensorflow/models/image/cifar10\n",
    "* 스터디 github 현재 경로에도(이 노트북과 같은 위치) 복사.\n",
    "* cifar10_eval_gpu.py는 cifar10_multi_gpu_train.py을 위한 원래 코드에서 설정을 조금 변경한 코드\n",
    "* 원 코드들의 로그 경로를(텐서보드용) 현재 경로상의 log 디렉토리로 변경.\n",
    "* 파이썬 코드들은 최대한 서버 터미널로 실행, 출력로그는 plog 확장자로 남김(노트북에서 실행하면 큰일) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar10.py\t     cifar10_input_test.py\t train.plog\r\n",
      "cifar10_eval.py      cifar10_multi_gpu_train.py  train_gpu.plog\r\n",
      "cifar10_eval_gpu.py  cifar10_train.py\r\n",
      "cifar10_input.py     eval_gpu.plog\r\n",
      "\r\n",
      "log:\r\n",
      "cifar10_eval  cifar10_eval_gpu\tcifar10_train  cifar10_train_gpu\r\n"
     ]
    }
   ],
   "source": [
    "!ls cifar10* log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_gpu.plog  train.plog  train_gpu.plog\r\n"
     ]
    }
   ],
   "source": [
    "!ls *.plog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oerview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The problem is to classify RGB 32x32 pixel images across 10 categories: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.tensorflow.org/versions/0.6.0/images/cifar_samples.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this tutorial is to build a relatively small convolutional neural network (CNN) for recognizing images. In the process, this tutorial:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Highlights a canonical organization for network architecture, training and evaluation.\n",
    "2. Provides a template for constructing larger and more sophisticated models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 32\n",
      "I tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 0 with properties: \n",
      "name: Tesla K40m\n",
      "major: 3 minor: 5 memoryClockRate (GHz) 0.745\n",
      "pciBusID 0000:06:00.0\n",
      "Total memory: 11.25GiB\n",
      "Free memory: 11.12GiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: 0 \n",
      "I tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 0:   Y \n",
      "I tensorflow/core/common_runtime/gpu/gpu_device.cc:702] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40m, pci bus id: 0000:06:00.0)\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Allocating 3.34GiB bytes.\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:52] GPU 0 memory begins at 0x42047a0000 extends to 0x42da041ccc\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.0KiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.0KiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.0KiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.0KiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.0KiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.0KiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.0KiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.0KiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.0KiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.0KiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00MiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00MiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00MiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00MiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00MiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.00MiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.00MiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.00MiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.00MiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.00MiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00GiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00GiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00GiB\n",
      "I tensorflow/core/common_runtime/direct_session.cc:60] Direct session inter op parallelism threads: 32\n",
      "W tensorflow/core/common_runtime/executor.cc:1071] 0x2fdc320 Compute status: Out of range: FIFOQueue '_0_fifo_queue' is closed and has insufficient elements (requested 1, current size 0)\n",
      "\t [[Node: ReaderRead = ReaderRead[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](FixedLengthRecordReader, fifo_queue)]]\n",
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 2.878s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python cifar10_input_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python cifar10_input.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 콘솔에서 실행하자\n",
    "python cifar10_train.py > train.plog 2>train.plog &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\r\n",
      "2016-02-03 09:49:56.909836: step 0, loss = 4.67 (2.0 examples/sec; 65.123 sec/batch)\r\n",
      "2016-02-03 09:50:02.208112: step 10, loss = 4.66 (272.5 examples/sec; 0.470 sec/batch)\r\n",
      "2016-02-03 09:50:06.935291: step 20, loss = 4.63 (309.4 examples/sec; 0.414 sec/batch)\r\n",
      "2016-02-03 09:50:11.677843: step 30, loss = 4.61 (269.0 examples/sec; 0.476 sec/batch)\r\n",
      "2016-02-03 09:50:16.492321: step 40, loss = 4.59 (261.3 examples/sec; 0.490 sec/batch)\r\n",
      "2016-02-03 09:50:21.212418: step 50, loss = 4.57 (286.6 examples/sec; 0.447 sec/batch)\r\n",
      "2016-02-03 09:50:25.903630: step 60, loss = 4.56 (289.0 examples/sec; 0.443 sec/batch)\r\n",
      "2016-02-03 09:50:30.640395: step 70, loss = 4.54 (277.4 examples/sec; 0.461 sec/batch)\r\n",
      "2016-02-03 09:50:35.276647: step 80, loss = 4.52 (287.4 examples/sec; 0.445 sec/batch)\r\n",
      "2016-02-03 09:50:39.996685: step 90, loss = 4.50 (262.0 examples/sec; 0.489 sec/batch)\r\n",
      "2016-02-03 09:50:44.778525: step 100, loss = 4.49 (265.7 examples/sec; 0.482 sec/batch)\r\n",
      "2016-02-03 09:50:50.061908: step 110, loss = 4.47 (251.3 examples/sec; 0.509 sec/batch)\r\n",
      "2016-02-03 09:50:54.755692: step 120, loss = 4.45 (263.3 examples/sec; 0.486 sec/batch)\r\n",
      "2016-02-03 09:50:59.488314: step 130, loss = 4.44 (263.5 examples/sec; 0.486 sec/batch)\r\n",
      "2016-02-03 09:51:04.253789: step 140, loss = 4.42 (261.3 examples/sec; 0.490 sec/batch)\r\n",
      "2016-02-03 09:51:08.937261: step 150, loss = 4.40 (270.0 examples/sec; 0.474 sec/batch)\r\n",
      "2016-02-03 09:51:13.708941: step 160, loss = 4.38 (249.0 examples/sec; 0.514 sec/batch)\r\n",
      "2016-02-03 09:51:18.442474: step 170, loss = 4.37 (258.0 examples/sec; 0.496 sec/batch)\r\n",
      "2016-02-03 09:51:23.275588: step 180, loss = 4.35 (265.4 examples/sec; 0.482 sec/batch)\r\n",
      "2016-02-03 09:51:28.006162: step 190, loss = 4.33 (285.9 examples/sec; 0.448 sec/batch)\r\n",
      "2016-02-03 09:51:32.802344: step 200, loss = 4.32 (256.5 examples/sec; 0.499 sec/batch)\r\n",
      "2016-02-03 09:51:38.099826: step 210, loss = 4.30 (280.5 examples/sec; 0.456 sec/batch)\r\n",
      "2016-02-03 09:51:42.990568: step 220, loss = 4.28 (263.1 examples/sec; 0.486 sec/batch)\r\n",
      "2016-02-03 09:51:47.820105: step 230, loss = 4.27 (272.3 examples/sec; 0.470 sec/batch)\r\n",
      "2016-02-03 09:51:52.601138: step 240, loss = 4.26 (264.9 examples/sec; 0.483 sec/batch)\r\n",
      "2016-02-03 09:51:57.459115: step 250, loss = 4.24 (268.1 examples/sec; 0.478 sec/batch)\r\n",
      "2016-02-03 09:52:02.282625: step 260, loss = 4.23 (307.4 examples/sec; 0.416 sec/batch)\r\n",
      "2016-02-03 09:52:07.126495: step 270, loss = 4.21 (257.8 examples/sec; 0.497 sec/batch)\r\n",
      "2016-02-03 09:52:11.859513: step 280, loss = 4.20 (266.1 examples/sec; 0.481 sec/batch)\r\n",
      "2016-02-03 09:52:16.667588: step 290, loss = 4.18 (248.7 examples/sec; 0.515 sec/batch)\r\n",
      "2016-02-03 09:52:21.574492: step 300, loss = 4.16 (247.8 examples/sec; 0.517 sec/batch)\r\n",
      "2016-02-03 09:52:26.942723: step 310, loss = 4.15 (267.4 examples/sec; 0.479 sec/batch)\r\n",
      "2016-02-03 09:52:31.706298: step 320, loss = 4.13 (259.0 examples/sec; 0.494 sec/batch)\r\n",
      "2016-02-03 09:52:36.519624: step 330, loss = 4.12 (262.5 examples/sec; 0.488 sec/batch)\r\n",
      "2016-02-03 09:52:41.310205: step 340, loss = 4.11 (251.1 examples/sec; 0.510 sec/batch)\r\n",
      "2016-02-03 09:52:46.121710: step 350, loss = 4.08 (254.0 examples/sec; 0.504 sec/batch)\r\n",
      "2016-02-03 09:52:50.893370: step 360, loss = 4.08 (260.9 examples/sec; 0.491 sec/batch)\r\n",
      "2016-02-03 09:52:55.716475: step 370, loss = 4.06 (244.4 examples/sec; 0.524 sec/batch)\r\n",
      "2016-02-03 09:53:00.545472: step 380, loss = 4.04 (251.5 examples/sec; 0.509 sec/batch)\r\n",
      "2016-02-03 09:53:05.449742: step 390, loss = 4.04 (271.5 examples/sec; 0.471 sec/batch)\r\n",
      "2016-02-03 09:53:10.233977: step 400, loss = 4.02 (278.6 examples/sec; 0.459 sec/batch)\r\n",
      "2016-02-03 09:53:15.588405: step 410, loss = 4.01 (246.4 examples/sec; 0.519 sec/batch)\r\n",
      "2016-02-03 09:53:20.445322: step 420, loss = 4.00 (261.2 examples/sec; 0.490 sec/batch)\r\n",
      "2016-02-03 09:53:25.282819: step 430, loss = 3.98 (250.3 examples/sec; 0.511 sec/batch)\r\n",
      "2016-02-03 09:53:30.082220: step 440, loss = 3.96 (270.3 examples/sec; 0.474 sec/batch)\r\n",
      "2016-02-03 09:53:34.905969: step 450, loss = 3.95 (285.9 examples/sec; 0.448 sec/batch)\r\n",
      "2016-02-03 09:53:39.758820: step 460, loss = 3.94 (269.6 examples/sec; 0.475 sec/batch)\r\n",
      "2016-02-03 09:53:44.546440: step 470, loss = 3.93 (281.4 examples/sec; 0.455 sec/batch)\r\n",
      "2016-02-03 09:53:49.392301: step 480, loss = 3.92 (251.8 examples/sec; 0.508 sec/batch)\r\n"
     ]
    }
   ],
   "source": [
    "!head train.plog -n 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python cifar10_eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python cifar10.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python cifar10_multi_gpu_train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=cnn_tensorboard/TensorBoard_0.html width=1000 height=900></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML('<iframe src=cnn_tensorboard/TensorBoard_0.html width=1000 height=900></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 참고자료\n",
    "* [1]\n",
    "* [2] https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

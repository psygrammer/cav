{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Descriptor Survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Local Binary Descriptors \n",
    "    - LBP\n",
    "    - BRISK\n",
    "    - FREAK\n",
    "* Spectra Descriptors    \n",
    "    - SIFT\n",
    "    - SURF\n",
    "    - Histogram of Gradients (HOG) and Variants\n",
    "    - PHOG and Related Methods\n",
    "    - Daisy and O-Daisy\n",
    "    - CARD\n",
    "    - Robust Fast Feature Matching\n",
    "    - RIFF, CHOG\n",
    "    - D-NETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Binary Descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LBP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig6.6.png\" width=600 />\n",
    "<img src=\"figures/fig6.7.png\" width=600 />\n",
    "<img src=\"figures/fig6.8.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LBP Summary Taxonomy\n",
    "\n",
    "* Spectra: Local binary\n",
    "* Feature shape: Square\n",
    "* Feature pattern: Pixel region compares with center pixel\n",
    "* Feature density: Local 3x3 at each pixel\n",
    "* Search method: Sliding window\n",
    "* Distance function: Hamming distance\n",
    "* Robustness: 3 (brightness, contrast, *rotation for RILBP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구현\n",
    "\n",
    "* http://www.bytefish.de/blog/local_binary_patterns/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BRISK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig4.10.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* BRISK [131,143] is a local binary method using a circular-symmetric pattern region shape and a total of 60 point-pairs as line segments arranged in four concentric rings, as shown in Figure 4-10 and described in detail in Chapter 4. \n",
    "* The method uses point-pairs of both short segments and long segments, and this provides a measure of scale invariance, since short segments may map better for fine resolution and long segments may map better at coarse resolution.\n",
    "* <font color=\"red\">The brisk algorithm is unique, using a novel FAST detector adapted to use scale space, reportedly achieving an order of magnitude performance increase over SURF with comparable accuracy.</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### main computational steps\n",
    "\n",
    "* Detects keypoints using FAST or AGHAST based selection in scale space.\n",
    "* Performs Gaussian smoothing at each pixel sample point to get the point value.\n",
    "* Makes three sets of pairs: long pairs, short pairs, and unused pairs (the unused pairs are not in the long pair or the short pair set; see Figure 4-12).\n",
    "* Computes gradient between long pairs, sums gradients to determine orientation\n",
    "* Uses gradient orientation to adjust and rotate short pairs.\n",
    "* Creates binary descriptor from short pair point-wise comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BRISK Summary Taxonomy\n",
    "\n",
    "* Spectra: Local binary + orientation vector\n",
    "*  Feature shape: Square\n",
    "*  Feature pattern: Trained local pixel point-pair compares\n",
    "*  Feature density: Local 31x31 at FAST interest points\n",
    "* Search method: Sliding window\n",
    "*  Distance function: Hamming distance\n",
    "*  <font color=\"red\">Robustness: 4 (brightness, contrast, rotation, scale)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구현 \n",
    "\n",
    "* Opencv - http://docs.opencv.org/modules/features2d/doc/feature_detection_and_description.html\n",
    "* http://www.asl.ethz.ch/people/lestefan/personal/BRISK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FREAK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig4.9.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FREAK Summary Taxonomy\n",
    "\n",
    "* Spectra: Local binary coarse-to-fine + orientation vector\n",
    "* Feature shape: Square\n",
    "* Feature pattern: 31x31 region pixel point-pair compares\n",
    "* Feature density: Sparse local at AGAST interest points\n",
    "* Search method: Sliding window over scale space\n",
    "* Distance function: Hamming distance\n",
    "* <font color=\"red\">Robustness: 6 (brightness, contrast, rotation, scale, viewpoint, blur) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구현 \n",
    "\n",
    "* Opencv - http://docs.opencv.org/modules/features2d/doc/feature_detection_and_description.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectra Descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SIFT\n",
    "* SURF\n",
    "* Histogram of Gradients (HOG) and Variants\n",
    "* PHOG and Related Methods\n",
    "* Daisy and O-Daisy\n",
    "* CARD\n",
    "* Robust Fast Feature Matching\n",
    "* RIFF, CHOG\n",
    "* Chain Code Histograms\n",
    "* D-NETS\n",
    "* Local Gradient Pattern\n",
    "* Local Phase Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig6.14.png\" width=600 />\n",
    "<img src=\"figures/fig6.15.png\" width=600 />\n",
    "<img src=\"figures/fig6.16.png\" width=600 />\n",
    "<img src=\"figures/fig6.17.png\" width=600 />\n",
    "<img src=\"figures/tbl6.2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SIFT Summary Taxonomy\n",
    "\n",
    "* Spectra: Local gradient magnitude + orientation\n",
    "* Feature shape: Square, with circular weighting\n",
    "* Feature pattern: Square with circular-symmetric weighting\n",
    "* Feature density: Sparse at local 16x16 DoG interest points\n",
    "* Search method: Sliding window over scale space\n",
    "* Distance function: Euclidean distance (*or Hellinger distance with RootSIFT retrofit)\n",
    "*  Robustness: 6 (brightness, contrast, rotation, scale, <font color=\"red\">affine transforms</font>, noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구현 \n",
    "\n",
    "* Opencv - http://docs.opencv.org/modules/nonfree/doc/feature_detection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SURF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig6.22.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SURF Summary Taxonomy\n",
    "\n",
    "* Spectra: Integral box filter + orientation vector\n",
    "* Feature shape: HAAR rectangles\n",
    "* Feature pattern: Dense\n",
    "* Feature density: Sparse at Hessian interest points\n",
    "* Search method: Dense sliding window over scale space\n",
    "* Distance function: Mahalanobis or Euclidean\n",
    "* <font color=\"red\">Robustness: 4 (scale, rotation, illumination, noise)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구현 \n",
    "\n",
    "* Opencv - http://docs.opencv.org/doc/tutorials/features2d/feature_detection/feature_detection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of Gradients (HOG) and Variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig4.12.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HOG Summary Taxonomy\n",
    "\n",
    "* Spectra: Local region gradient histograms\n",
    "* Feature shape: Rectangle or circle\n",
    "* Feature pattern: Dense 64x128 typical rectangle\n",
    "* Feature density: Dense overlapping blocks\n",
    "* Search method: Grid over scale space\n",
    "* Distance function: Euclidean\n",
    "* <font color=\"red\">Robustness: 4 (illumination, viewpoint, scale, noise)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구현\n",
    "\n",
    "* OpenCV - http://docs.opencv.org/modules/gpu/doc/object_detection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PHOG and Related Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig6.23.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Pyramid Histogram of Oriented Gradients (PHOG) [191] method is <font color=\"red\">designed for global or regional image classification, rather than local feature detection</font>. \n",
    "* PHOG combines regional HOG features with whole image area features using spatial relationships between features spread across the entire image in an octave grid region subdivision; see Figure 6-23.\n",
    "* PHOG is similar to related work using a coarse-to-fine grid of region histograms called Spatial Pyramid Matching by Lazebni, Schmid, and Ponce [534], using histograms of oriented edges and SIFT features to provide multi-class classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PHOG Summary Taxonomy\n",
    "\n",
    "* Spectra: Global and regional gradient orientation histograms\n",
    "* Feature shape: Rectangle\n",
    "* Feature pattern: Dense grid of tiles\n",
    "* Feature density: Dense tiles\n",
    "* Search method: Grid regions, no searching\n",
    "* Distance function: l2 norm\n",
    "* <font color=\"red\">Robustness: 3 (image classification under some invariance to illumination, viewpoint, noise)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daisy and O-Daisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig6.24.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Daisy Descriptor [214.309] is inspired by SIFT and GLOH-like descriptors, and is <font color=\"red\">devised for dense-matching applications such as stereo mapping and tracking</font>, reported to be about <font color=\"red\">40 percent faster than SIFT.</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Daisy Summary Taxonomy\n",
    "\n",
    "* Spectra: Gaussian convolution values\n",
    "* Feature shape: Circular\n",
    "* Feature pattern: Overlapping concentric circular\n",
    "* Feature density: Dense at each pixel\n",
    "* Search method: Dense sliding window\n",
    "* Distance function: Euclidean\n",
    "* <font color=\"red\">Robustness: 3 (illumination, occlusion, noise)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구현 \n",
    "\n",
    "* Opencv - http://docs.opencv.org/3.0.0/dc/daa/xfeatures2d_8hpp.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CARD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig6.25.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Compact and Realtime Descriptor (CARD) method [218] is designed with performance optimizations in mind, using learning-based sparse hashing to convert descriptors into binary codes supporting fast Hamming distance matching.\n",
    "* CARD is reported to achieve <font color=\"red\">significantly better rotation and scale robustness compared to SIFT and SURF</font>, with performance at least <font color=\"red\">ten times better than SIFT and slightly better than SURF</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CARD Summary Taxonomy\n",
    "\n",
    "* Spectra: Gradient magnitude and direction\n",
    "* Feature shape: Circular, variable sized based on pyramid scale and principal orientation\n",
    "* Feature pattern: Dense\n",
    "* Feature density: Sparse at FAST interest points over image pyramid\n",
    "* Search method: Sliding window\n",
    "* Distance function: Hamming\n",
    "* <font color=\"red\">Robustness: 3 (illumination, scale, rotation)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구현 \n",
    "\n",
    "* https://github.com/DensoITLab/CARD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Fast Feature Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig6.26.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=\"red\">Robust Feature Matching in 2.3us developed by Taylor, Rosten and Drummond [220] (RFM2.3) (this acronym is coined here by the author) is a novel, fast method of feature description and matching, optimized for both compute speed and memory footprint.</font>\n",
    "* RFM2.3 stands alone among the feature descriptors surveyed here with regard to the combination of methods and optimizations employed, including sparse region histograms and binary feature codes.\n",
    "* <font color=\"red\">The resulting descriptor is a compressed, binary encoded bit vector suitable for Hamming distance.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFM2.3 Summary Taxonomy\n",
    "\n",
    "* Spectra: Normalized histogram patch intensity encoded into binary patch index code\n",
    "* Feature shape: Rectangular, multiple viewpoints\n",
    "* Feature pattern: Sparse patterns in 15x15 pixel patch\n",
    "* Feature density: Sparse at FAST9 interest points\n",
    "* Search method: Sliding window over image pyramid\n",
    "* Distance function: Hamming\n",
    "* <font color=\"red\">Robustness: 4 (illumination, scale, rotation, viewpoint)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RIFF, CHOG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig6.27.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Rotation Invariant Fast Features (RIFF) [222][219] method is <font color=\"red\">motivated by tracking and mapping applications in mobile augmented reality</font>. The basis of the RIFF method includes the development of a radial gradient transform (RGT), which expresses gradient orientation and magnitude in a compute-efficient and rotationally invariant fashion.\n",
    "* Another contribution of RIFF is a tracking method, which is reported to be more accurate than KLT with 26x better performance. <font color=\"red\">RIFF is reported to be 15x faster than SURF</font>. \n",
    "* RIFF uses a HOG descriptor computed at FAST interest points located in scale space, and generally follows the method of the author’s previous work in CHOG [223] (compressed HOG) for reduced dimensionality, low bitrate binning. Prior to binning the HOG gradients, a radial gradient transform (RGT) is used to create a rotationally invariant gradient format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RIFF Summary Taxonomy\n",
    "\n",
    "* Spectra: Local region histogram of approximated radial gradients\n",
    "* Feature shape: Circular\n",
    "* Feature pattern: Sparse every other pixel\n",
    "* Feature density: Sparse at FAST interest points over image pyramid\n",
    "* Search method: Sliding window\n",
    "* Distance function: Symmetric KL-divergence\n",
    "* <font color=\"red\">Robustness: 4 (illumination, scale, rotation, viewpoint)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D-NETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig4.8.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The D-NETS (Descriptor-NETS) [135] approach developed by Hundelshausen and Sukthankar abandons patch or rectangular descriptor regions in favor of a set of strips connected at endpoints. \n",
    "* D-NETS allows for a family of strip patterns composed of directed graphs between a set of endpoints; it does not specifically limit the types of endpoints or strip patterns that may be used. \n",
    "* <font color=\"red\">Descriptor matching makes use of an efficient and novel hashing</font> and hypothesis correspondence <font color=\"red\">voting</font> method. <font color=\"red\">D-NETS results are reported to be higher in precision and recall than ORB or SIFT</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D-NETS Summary Taxonomy\n",
    "\n",
    "* Spectra: Normalized, averaged linear pixel intensity chunks\n",
    "* Feature shape: Line segment connected networks\n",
    "* Feature pattern: Sparse line segments between chosen points\n",
    "* Feature density: Sparse along lines\n",
    "* Search method: Sliding window\n",
    "* Distance function: Hashing and voting\n",
    "* <font color=\"red\">Robustness: 5 (illumination, scale, rotation, viewpoint, occlusion)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구현\n",
    "\n",
    "* https://sites.google.com/site/descriptornets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Computer Vision Metrics: Survey, Taxonomy, and Analysis - http://www.amazon.com/Computer-Vision-Metrics-Taxonomy-Analysis/dp/1430259299/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

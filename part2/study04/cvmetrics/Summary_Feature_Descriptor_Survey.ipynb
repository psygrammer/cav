{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Descriptor Survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Local Binary Descriptors \n",
    "    - LBP\n",
    "    - BRISK\n",
    "    - FREAK\n",
    "* Spectra Descriptors    \n",
    "    - SIFT\n",
    "    - SURF\n",
    "    - Histogram of Gradients (HOG) and Variants\n",
    "    - PHOG and Related Methods\n",
    "    - Daisy and O-Daisy\n",
    "    - CARD\n",
    "    - Robust Fast Feature Matching\n",
    "    - RIFF, CHOG\n",
    "    - D-NETS\n",
    "    - LIOP\n",
    "* Polygon Shape Descriptors\n",
    "    - MSER Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Binary Descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LBP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig6.6.png\" width=600 />\n",
    "<img src=\"figures/fig6.7.png\" width=600 />\n",
    "<img src=\"figures/fig6.8.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LBP Summary Taxonomy\n",
    "\n",
    "* Spectra: Local binary\n",
    "* Feature shape: Square\n",
    "* Feature pattern: Pixel region compares with center pixel\n",
    "* Feature density: Local 3x3 at each pixel\n",
    "* Search method: Sliding window\n",
    "* Distance function: Hamming distance\n",
    "* Robustness: 3 (brightness, contrast, *rotation for RILBP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구현\n",
    "\n",
    "* http://www.bytefish.de/blog/local_binary_patterns/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BRISK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig4.10.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* BRISK [131,143] is a local binary method using a circular-symmetric pattern region shape and a total of 60 point-pairs as line segments arranged in four concentric rings, as shown in Figure 4-10 and described in detail in Chapter 4. \n",
    "* The method uses point-pairs of both short segments and long segments, and this provides a measure of scale invariance, since short segments may map better for fine resolution and long segments may map better at coarse resolution.\n",
    "* <font color=\"red\">The brisk algorithm is unique, using a novel FAST detector adapted to use scale space, reportedly achieving an order of magnitude performance increase over SURF with comparable accuracy.</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### main computational steps\n",
    "\n",
    "* Detects keypoints using FAST or AGHAST based selection in scale space.\n",
    "* Performs Gaussian smoothing at each pixel sample point to get the point value.\n",
    "* Makes three sets of pairs: long pairs, short pairs, and unused pairs (the unused pairs are not in the long pair or the short pair set; see Figure 4-12).\n",
    "* Computes gradient between long pairs, sums gradients to determine orientation\n",
    "* Uses gradient orientation to adjust and rotate short pairs.\n",
    "* Creates binary descriptor from short pair point-wise comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BRISK Summary Taxonomy\n",
    "\n",
    "* Spectra: Local binary + orientation vector\n",
    "*  Feature shape: Square\n",
    "*  Feature pattern: Trained local pixel point-pair compares\n",
    "*  Feature density: Local 31x31 at FAST interest points\n",
    "* Search method: Sliding window\n",
    "*  Distance function: Hamming distance\n",
    "*  <font color=\"red\">Robustness: 4 (brightness, contrast, rotation, scale)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구현 \n",
    "\n",
    "* Opencv - http://docs.opencv.org/modules/features2d/doc/feature_detection_and_description.html\n",
    "* http://www.asl.ethz.ch/people/lestefan/personal/BRISK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FREAK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig4.9.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FREAK Summary Taxonomy\n",
    "\n",
    "* Spectra: Local binary coarse-to-fine + orientation vector\n",
    "* Feature shape: Square\n",
    "* Feature pattern: 31x31 region pixel point-pair compares\n",
    "* Feature density: Sparse local at AGAST interest points\n",
    "* Search method: Sliding window over scale space\n",
    "* Distance function: Hamming distance\n",
    "* <font color=\"red\">Robustness: 6 (brightness, contrast, rotation, scale, viewpoint, blur) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구현 \n",
    "\n",
    "* Opencv - http://docs.opencv.org/modules/features2d/doc/feature_detection_and_description.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectra Descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SIFT\n",
    "* GLOH\n",
    "* SIFT-GLOH\n",
    "* SURF\n",
    "* Histogram of Gradients (HOG) and Variants\n",
    "* PHOG and Related Methods\n",
    "* Daisy and O-Daisy\n",
    "* CARD\n",
    "* Robust Fast Feature Matching\n",
    "* RIFF, CHOG\n",
    "* Chain Code Histograms\n",
    "* D-NETS\n",
    "* Local Gradient Pattern\n",
    "* Local Phase Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig6.14.png\" width=600 />\n",
    "<img src=\"figures/fig6.15.png\" width=600 />\n",
    "<img src=\"figures/fig6.16.png\" width=600 />\n",
    "<img src=\"figures/fig6.17.png\" width=600 />\n",
    "<img src=\"figures/tbl6.2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SIFT Summary Taxonomy\n",
    "\n",
    "* Spectra: Local gradient magnitude + orientation\n",
    "* Feature shape: Square, with circular weighting\n",
    "* Feature pattern: Square with circular-symmetric weighting\n",
    "* Feature density: Sparse at local 16x16 DoG interest points\n",
    "* Search method: Sliding window over scale space\n",
    "* Distance function: Euclidean distance (*or Hellinger distance with RootSIFT retrofit)\n",
    "*  Robustness: 6 (brightness, contrast, rotation, scale, <font color=\"red\">affine transforms</font>, noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구현 \n",
    "\n",
    "* Opencv - http://docs.opencv.org/modules/nonfree/doc/feature_detection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLOH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Gradient Location and Orientation Histogram \n",
    "* [VGG - Eval Local]에 따르면 GLOH가 SIFT 보다 더 좋다고 나옴\n",
    "* 그러나 [주]에 SHIFT-GLOH가 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT-GLOH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Gradient Location and Orientation Histogram (GLOH) [144] method uses polar coordinates and radially distributed bins rather than the Cartesian coordinate style histogram binning method used by SIFT. It is reported to provide greater accuracy and robustness over SIFT and other descriptors for some ground truth datasets [144]. As shown in Figure 6-17, GLOH uses a set of 17 radially distributed bins to sum the gradient information in polar coordinates, yielding a 272-bin histogram. The center bin is not direction oriented. The size of the descriptor is reduced using PCA. GLOH has been used to retrofit SIFT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SURF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig6.22.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SURF Summary Taxonomy\n",
    "\n",
    "* Spectra: Integral box filter + orientation vector\n",
    "* Feature shape: HAAR rectangles\n",
    "* Feature pattern: Dense\n",
    "* Feature density: Sparse at Hessian interest points\n",
    "* Search method: Dense sliding window over scale space\n",
    "* Distance function: Mahalanobis or Euclidean\n",
    "* <font color=\"red\">Robustness: 4 (scale, rotation, illumination, noise)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구현 \n",
    "\n",
    "* Opencv - http://docs.opencv.org/doc/tutorials/features2d/feature_detection/feature_detection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of Gradients (HOG) and Variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig4.12.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HOG Summary Taxonomy\n",
    "\n",
    "* Spectra: Local region gradient histograms\n",
    "* Feature shape: Rectangle or circle\n",
    "* Feature pattern: Dense 64x128 typical rectangle\n",
    "* Feature density: Dense overlapping blocks\n",
    "* Search method: Grid over scale space\n",
    "* Distance function: Euclidean\n",
    "* <font color=\"red\">Robustness: 4 (illumination, viewpoint, scale, noise)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구현\n",
    "\n",
    "* OpenCV - http://docs.opencv.org/modules/gpu/doc/object_detection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PHOG and Related Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig6.23.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Pyramid Histogram of Oriented Gradients (PHOG) [191] method is <font color=\"red\">designed for global or regional image classification, rather than local feature detection</font>. \n",
    "* PHOG combines regional HOG features with whole image area features using spatial relationships between features spread across the entire image in an octave grid region subdivision; see Figure 6-23.\n",
    "* PHOG is similar to related work using a coarse-to-fine grid of region histograms called Spatial Pyramid Matching by Lazebni, Schmid, and Ponce [534], using histograms of oriented edges and SIFT features to provide multi-class classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PHOG Summary Taxonomy\n",
    "\n",
    "* Spectra: Global and regional gradient orientation histograms\n",
    "* Feature shape: Rectangle\n",
    "* Feature pattern: Dense grid of tiles\n",
    "* Feature density: Dense tiles\n",
    "* Search method: Grid regions, no searching\n",
    "* Distance function: l2 norm\n",
    "* <font color=\"red\">Robustness: 3 (image classification under some invariance to illumination, viewpoint, noise)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daisy and O-Daisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig6.24.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Daisy Descriptor [214.309] is inspired by SIFT and GLOH-like descriptors, and is <font color=\"red\">devised for dense-matching applications such as stereo mapping and tracking</font>, reported to be about <font color=\"red\">40 percent faster than SIFT.</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Daisy Summary Taxonomy\n",
    "\n",
    "* Spectra: Gaussian convolution values\n",
    "* Feature shape: Circular\n",
    "* Feature pattern: Overlapping concentric circular\n",
    "* Feature density: Dense at each pixel\n",
    "* Search method: Dense sliding window\n",
    "* Distance function: Euclidean\n",
    "* <font color=\"red\">Robustness: 3 (illumination, occlusion, noise)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구현 \n",
    "\n",
    "* Opencv - http://docs.opencv.org/3.0.0/dc/daa/xfeatures2d_8hpp.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CARD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig6.25.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Compact and Realtime Descriptor (CARD) method [218] is designed with performance optimizations in mind, using learning-based sparse hashing to convert descriptors into binary codes supporting fast Hamming distance matching.\n",
    "* CARD is reported to achieve <font color=\"red\">significantly better rotation and scale robustness compared to SIFT and SURF</font>, with performance at least <font color=\"red\">ten times better than SIFT and slightly better than SURF</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CARD Summary Taxonomy\n",
    "\n",
    "* Spectra: Gradient magnitude and direction\n",
    "* Feature shape: Circular, variable sized based on pyramid scale and principal orientation\n",
    "* Feature pattern: Dense\n",
    "* Feature density: Sparse at FAST interest points over image pyramid\n",
    "* Search method: Sliding window\n",
    "* Distance function: Hamming\n",
    "* <font color=\"red\">Robustness: 3 (illumination, scale, rotation)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구현 \n",
    "\n",
    "* https://github.com/DensoITLab/CARD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Fast Feature Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig6.26.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=\"red\">Robust Feature Matching in 2.3us developed by Taylor, Rosten and Drummond [220] (RFM2.3) (this acronym is coined here by the author) is a novel, fast method of feature description and matching, optimized for both compute speed and memory footprint.</font>\n",
    "* RFM2.3 stands alone among the feature descriptors surveyed here with regard to the combination of methods and optimizations employed, including sparse region histograms and binary feature codes.\n",
    "* <font color=\"red\">The resulting descriptor is a compressed, binary encoded bit vector suitable for Hamming distance.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFM2.3 Summary Taxonomy\n",
    "\n",
    "* Spectra: Normalized histogram patch intensity encoded into binary patch index code\n",
    "* Feature shape: Rectangular, multiple viewpoints\n",
    "* Feature pattern: Sparse patterns in 15x15 pixel patch\n",
    "* Feature density: Sparse at FAST9 interest points\n",
    "* Search method: Sliding window over image pyramid\n",
    "* Distance function: Hamming\n",
    "* <font color=\"red\">Robustness: 4 (illumination, scale, rotation, viewpoint)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RIFF, CHOG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig6.27.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Rotation Invariant Fast Features (RIFF) [222][219] method is <font color=\"red\">motivated by tracking and mapping applications in mobile augmented reality</font>. The basis of the RIFF method includes the development of a radial gradient transform (RGT), which expresses gradient orientation and magnitude in a compute-efficient and rotationally invariant fashion.\n",
    "* Another contribution of RIFF is a tracking method, which is reported to be more accurate than KLT with 26x better performance. <font color=\"red\">RIFF is reported to be 15x faster than SURF</font>. \n",
    "* RIFF uses a HOG descriptor computed at FAST interest points located in scale space, and generally follows the method of the author’s previous work in CHOG [223] (compressed HOG) for reduced dimensionality, low bitrate binning. Prior to binning the HOG gradients, a radial gradient transform (RGT) is used to create a rotationally invariant gradient format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RIFF Summary Taxonomy\n",
    "\n",
    "* Spectra: Local region histogram of approximated radial gradients\n",
    "* Feature shape: Circular\n",
    "* Feature pattern: Sparse every other pixel\n",
    "* Feature density: Sparse at FAST interest points over image pyramid\n",
    "* Search method: Sliding window\n",
    "* Distance function: Symmetric KL-divergence\n",
    "* <font color=\"red\">Robustness: 4 (illumination, scale, rotation, viewpoint)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D-NETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig4.8.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The D-NETS (Descriptor-NETS) [135] approach developed by Hundelshausen and Sukthankar abandons patch or rectangular descriptor regions in favor of a set of strips connected at endpoints. \n",
    "* D-NETS allows for a family of strip patterns composed of directed graphs between a set of endpoints; it does not specifically limit the types of endpoints or strip patterns that may be used. \n",
    "* <font color=\"red\">Descriptor matching makes use of an efficient and novel hashing</font> and hypothesis correspondence <font color=\"red\">voting</font> method. <font color=\"red\">D-NETS results are reported to be higher in precision and recall than ORB or SIFT</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D-NETS Summary Taxonomy\n",
    "\n",
    "* Spectra: Normalized, averaged linear pixel intensity chunks\n",
    "* Feature shape: Line segment connected networks\n",
    "* Feature pattern: Sparse line segments between chosen points\n",
    "* Feature density: Sparse along lines\n",
    "* Search method: Sliding window\n",
    "* Distance function: Hashing and voting\n",
    "* <font color=\"red\">Robustness: 5 (illumination, scale, rotation, viewpoint, occlusion)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구현\n",
    "\n",
    "* https://sites.google.com/site/descriptornets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://zhwang.me/publication/liop/images/fig1.jpg\" wdith=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.vlfeat.org/api/liop.png\" width=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Local Invariant Order Pattern (LIOP) descriptor [32] is a local image descriptor based on the concept of local order pattern*. An order pattern is simply the order obtained by sorting selected image samples by increasing intensity. \n",
    "* An advantage of order patterns is that they are invariant to monotonic changes of the image intensity. However, an order pattern describes only a small portion of a patch and is not very distinctive. LIOP assembles local order patterns computed at all image locations to obtain a descriptor that at the same time distinctive and invariant to monotonic intensity changes as well as image rotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [LIOP-주]에서는 다른 것에 비해 월등히 성능이 좋다고 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://zhwang.me/publication/liop/images/Resutls.jpg\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LIOP Summary Taxonomy\n",
    "\n",
    "* Spectra: \n",
    "* Feature shape: \n",
    "* Feature pattern: \n",
    "* Feature density: \n",
    "* Search method: \n",
    "* Distance function: \n",
    "* <font color=\"red\">Robustness: 4 (illumination, scale, rotation, viewpoint, blur(?) ) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구현\n",
    "\n",
    "* 논문 저자 코드 - http://zhwang.me/publication/liop/\n",
    "* VLFeat - http://www.vlfeat.org/api/liop.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polygon Shape Descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MSER Method [주] = Affine Covariant Regions [[VGG - Affine Covariant Regions]]\n",
    "    - MSER \n",
    "* Shape Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSER Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Maximally Stable Extremal Regions (MSER) method [194] is usually discussed in the literature as an interest region detector, and in fact it is. However we include MSER in the shape descriptor section because MSER regions can be much larger than other interest point methods, such as HARRIS or FAST.\n",
    "* The MSER can also be considered as the basis for a shape descriptor, and as an  alternative to morphological methods of segmentation. Each MSER region can be analyzed and described using shape metrics, as discussed later in this chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affine Covariant Regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.robots.ox.ac.uk/~vgg/research/affine/det_eval_files/har_regions4.gif\" width=400 />\n",
    "<img src=\"http://www.robots.ox.ac.uk/~vgg/research/affine/det_eval_files/har_regions4.gif\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSER Summary Taxonomy\n",
    "\n",
    "* Spectra: \n",
    "* Feature shape: \n",
    "* Feature pattern: \n",
    "* Feature density: \n",
    "* Search method: \n",
    "* Distance function: \n",
    "* <font color=\"red\">Robustness: 5 (illumination, scale, rotation, viewpoint, affine transform) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구현\n",
    "\n",
    "* OpenCV - http://docs.opencv.org/modules/features2d/doc/feature_detection_and_description.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DaLI (Deformation and Light Invariant Descriptor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* DaLI descriptors are local image patch representations that have been shown to be robust to deformation and strong illumination changes. These descriptors are constructed by treating the <font color=\"red\">image patch as a 3D surface</font> and then simulating the diffusion of heat along the surface for different intervals of time. Small time intervals represent local deformation properties while large time intervals represent global deformation properties. Additionally, by performing a logarithmic sampling and then a <font color=\"red\">Fast Fourier Transform</font>, it is possible to obtain robustness against non-linear illumination changes. We have created the first feature point dataset that focuses on deformation and illumination changes of real world objects in order to perform evaluation, where we show the DaLI descriptors outperform all the widely used descriptors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.iri.upc.edu/people/esimo/images/dali/dali_flowchart.png\" width=800 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DaLI Summary Taxonomy\n",
    "\n",
    "* Spectra: \n",
    "* Feature shape: \n",
    "* Feature pattern: \n",
    "* Feature density: \n",
    "* Search method: \n",
    "* Distance function: \n",
    "* <font color=\"red\">Robustness: 6? (brightness?, contrast?, rotation, scale, affine transforms, noise?) </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구현 \n",
    "\n",
    "* https://github.com/bobbens/DaLI\n",
    "* http://www.iri.upc.edu/people/esimo/en/research/dali/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [주] Computer Vision Metrics: Survey, Taxonomy, and Analysis - http://www.amazon.com/Computer-Vision-Metrics-Taxonomy-Analysis/dp/1430259299/\n",
    "* [LIOP-주] Local Intensity Order Pattern for Feature Description - http://zhwang.me/publication/liop/\n",
    "* [LIOP-보조] LIOP fundamentals - http://www.vlfeat.org/api/liop-fundamentals.html\n",
    "* [VGG - Affine Covariant Regions] Affine Covariant Regions - http://www.robots.ox.ac.uk/~vgg/research/affine/\n",
    "* [VGG - Eval Region] - K. Mikolajczyk, T. Tuytelaars, C. Schmid, A. Zisserman, J. Matas, F. Schaffalitzky, T. Kadir and L. Van Gool, A comparison of affine region detectors. In IJCV 65(1/2):43-72, 2005. - http://www.robots.ox.ac.uk/~vgg/research/affine/det_eval_files/vibes_ijcv2004.pdf\n",
    "* [VGG - Eval Local] - K. Mikolajczyk, C. Schmid,  A performance evaluation of local descriptors. In PAMI 27(10):1615-1630 . - http://www.robots.ox.ac.uk/~vgg/research/affine/det_eval_files/mikolajczyk_pami2004.pdf\n",
    "* [MSER] https://en.wikipedia.org/wiki/Maximally_stable_extremal_regions\n",
    "* [DaLI-주] http://www.iri.upc.edu/people/esimo/en/research/dali/\n",
    "* [DaLI-2015] http://www.iri.upc.edu/people/esimo/publications/SimoSerraIJCV2015.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
